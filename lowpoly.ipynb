{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2 as cv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial import Delaunay\n",
    "from PIL import Image, ImageOps, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Load Image-------------------------------------\n",
    "img_name = 'beatles_-_abbey_road.jpg'\n",
    "img = Image.open('beatles_-_abbey_road.jpg')\n",
    "width, height = img.size\n",
    "img_np = img.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Determine probability that pixel gets point dropped-------------------------------------------------------\n",
    "\n",
    "#a) Create two 2D arrays the same size as the img array\n",
    "#b) Calculate the gradient of a pixel (based on some number of neighbors) [for now, we'll just say that |gradient| > x, but worth looking into whether Laplacian Zero crossing is greater than a threshold]\n",
    "#c) Use this to find Laplacian Zero crossings of 3x3 patches\n",
    "#d) Plot zero-crossings whose strength are greater than a threshold\n",
    "    #Note: This means-- normalize strength of zero-crossing such that it's between [0, 1]-- this is percent chance it gets a point plotted\n",
    "    #If there isn't a zero-crossing, the gradient will be low so either have a fixed probability or use some factor of the gradient\n",
    "#e) Put these probabilities into 2D array\n",
    "\n",
    "ddepth = cv.CV_16S\n",
    "kernel_size = 3\n",
    "src = cv.imread(cv.samples.findFile(img_name), cv.IMREAD_COLOR)\n",
    "src = cv.GaussianBlur(src, (3, 3), 0)\n",
    "src_grey = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "dst = cv.Laplacian(src_grey, ddepth, ksize=kernel_size)\n",
    "img_edges = cv.convertScaleAbs(dst)\n",
    "#cv.imshow(\"\", img_edges)\n",
    "#cv.waitKey(0)\n",
    "chances = img_edges/255\n",
    "n = 5000\n",
    "#Need tuple for some stuff and list for others\n",
    "\n",
    "\n",
    " \n",
    "#sample1=pd.DataFrame(data=chances).stack().sort_values(ascending=False)[0:n].sample(n//2).index[0:n//2]\n",
    "#sample2=pd.DataFrame(data=chances).stack().sort_values(ascending=False)[0:n].sample(n//2).index[0:n//2]\n",
    "#max_index = sample1.append(sample2)\n",
    "max_index = pd.DataFrame(data=chances).stack().sort_values(ascending=False).index[0:n]\n",
    "x = max_index.get_level_values(1)\n",
    "y = max_index.get_level_values(0)\n",
    "\n",
    "coords = [(i, j) for i, j in zip(x, y)]\n",
    "coords_reverse = [(j, i) for i, j in zip(x, y)]\n",
    "coord_list = [[i, j] for i, j in zip(x, y)]\n",
    "triangulate_coords = [(i, height-j) for i, j in zip(x, y)]\n",
    "\n",
    "chance_array = pd.DataFrame(data=chances)\n",
    "#chance_array.hood = \n",
    "#unique_vals = pd.DataFrame(data=chances).stack().unique()\n",
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIL indexes [col, row], or [y, x]\n",
    "Delaunay indexes [x, y], starting from 0\n",
    "\n",
    "Need to figure out how to unpack it to make it triangulate the correct way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Create new PIL image and plot points\n",
    "\n",
    "pic = Image.new(mode = \"RGB\", size=(width, height))\n",
    "draw = ImageDraw.Draw(pic)\n",
    "draw.point(coords)\n",
    "pic.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIL (draw): Start at upper left corner, index right and down (col, row)\n",
    "Delaunay (tri): Start at lower left corner, index right and up (col, height - row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)Delaunay Triangulation---------------------------------------------------------------------------------------\n",
    "\n",
    "tri = Delaunay(coords)\n",
    "test = pd.DataFrame(data = coords)\n",
    "#draw.polygon(tri.simplices)\n",
    "new_coords = np.array(coords)\n",
    "#i=0\n",
    "for triangle in new_coords[tri.simplices]:\n",
    "    row = triangle[1].tolist()[0]\n",
    "    col = triangle[1].tolist()[1]\n",
    "    color = img_np[col, row]\n",
    "    draw.polygon([(triangle[0].tolist()[1], triangle[0].tolist()[0]), (triangle[1].tolist()[1], triangle[1].tolist()[0]), (triangle[2].tolist()[1], triangle[2].tolist()[0])], fill=color)\n",
    "    #i += 1\n",
    "pic.show()\n",
    "#new_coords[tri.simplices][0][1].tolist()[0]\n",
    "#coords\n",
    "#Note: We may use a different file here, and we're gonna use the neural network outlined in that research paper (find on Notion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('polynate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7862d127e24b818d46a6f8d0257fb66f297aa6fa14c5a9c2fdf6cf2a5ab55ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
